<HTML>
  <HEAD>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <style>
      table {
	  width:90%;
	  position:relative;
	  left:5%;
	  border-collapse: collapse;
	  border-width:1px;
	  padding:10px;
      }
      td {
	  padding: 10px;
	  font-family:'Sans';
      }
      li {
	  padding: 10px;
	  font-family:'Sans';
	  line-height: 150%;
	  text-align: justify;
      }
      p {
	  padding: 10px;
	  font-family:'Sans';
	  line-height: 150%;
	  font-size:12pt;
	  text-align: justify;
      }
      h1 {
	  padding: 10px;
	  font-family:'Sans';
	  line-height: 150%;
	  font-size:12pt;
	  text-align: center;
      }
      h2 {
	  padding: 10px;
	  font-family:'Sans';
	  line-height: 150%;
	  font-size:12pt;
	  text-align: left;
      }
      h3 {
	  padding: 10px;
	  font-family:'Sans';
	  line-height: 150%;
	  font-size:12pt;
	  text-align: left;
      }
      h4{
	  padding: 10px;
	  font-family:'Sans';
	  line-height: 150%;
	  font-size:12pt;
	  text-align: left;
      }
    </style>
    
  </HEAD>
  
  <body>
    <h1>Planteamiento del Problema</h1>
    <p id="dos"> La Descentralización ha sido un principio guía en el desarrollo de Aplicaciones y Mecanismos a ser usados en Internet (<a href="#bib4">Cerf 2012</a>), el protocolo de transferencia de Archivos (FTP), los protocolos de correo (IMAP, POP3 y SMTP) y el protocolo de Hipertexto (HTTP) hacen posible la transmisión de recursos y mensajes sin necesidad de estar registrados en nominas o listas, o solicitar permiso permiso para hacerlo a organismo alguno, cualquier computadora conectada a internet (y, como se ha dicho cualquier computadora tiene la posibilidad dadas las capacidades técnicas correctas - hardware, etc. y la posibilidad de acceder a los mecanismos de conexión - ISP, ultima milla) tiene la capacidad de compartir (hacer de servidor de los protocolos mencionados) y acceder a (hacer de cliente de los protocolos mencionados) cualquier recurso.</p>
    <p id="cuantro"> Durante la Década entre 2000 y 2010 el mundo fue testigo de una transformación en el uso Web, fenómeno que los medios denominaron Web 2.0, sin razones técnicas para hacerlo, los mecanismos de la Web no cambiaron  (<a href="#bib4">Cerf 2012</a>), primero, la explosión inevitable de la "burbuja punto com" (2001), dejó pocas compañías sobrevivientes para hacer comercio en linea (origen de Amazon, Ebay y Paypal), esta explosión tuvo además como consecuencia el decremento en el registro de paginas personales, debido a que durante la inflación de la burbuja una de los principales incentivos para crear paginas era el comercio en linea, éste se convirtió en una industria altamente tecnificada, con compañías que prometían proteger a sus empresas clientes de daños similares a las víctimas de la explosión de la burbuja, esto aunado al incremento de atención en las noticias a actos vandálicos, criminales o sencillamente bromas pesadas de personas que aprovechaban de vulnerabilidades de seguridad en programas de servidor web populares (lo que los medios denominaron Hacking, a partir una concepción errónea del nombre -<a href="#bib7">Stallman 2002</a>, que se proliferó y aún, en 2020 se encuentra presente en los medios), incrementó el misticismo en esta industria, la recomendación canónica para las empresas fue encargar a empresas especialistas el diseño y mantenimiento de páginas web tanto de e-comerce como institucionales, sin embargo estas recomendaciones abarcaron el espectro de noticias y los usuarios sin conocimientos técnicos las acogieron por igual, percibiendo la instalación de estas aplicaciones en computadores personales como difícil y peligrosa. En respuesta a estos problemas surgieron "depositarios" (deposit), sitios web cuya única función era la de guardar, resguardar y permitir compartir recursos almacenados en su servidor, a través de programas que corrían en el navegador, para los usuarios sin conocimientos técnicos, estos sitios representaron la respuesta para la divulgación de contenidos sin comprometer el computador personal, la compañía que administra el servidor se haría cargo del software y seguridad, con la promesa de ofrecer resguardo y seguridad a los archivos, los usuarios se conectarían a estos sitios como clientes y le darían el control de recurso al sitio web, transfiriendo el contenido a sus servidores, el más famoso de estos sitios web fue sin duda megaupload, que no solo era popular entre millones de usuarios sino se convirtió en bandera para la auto publicación de artistas y contaba entre sus usuarios y patrocinantes a músicos populares, estrellas de cine, etc. Estos sitios web, una vez populares llamaron la atención de las grandes corporaciones gracias a que muchos usuarios usaban estos servicios para almacenar y distribuir material con copyright, y, eventualmente fueron cerrados y sus archivos confiscados, el caso mas notorio de estos fue, de nuevo, megaupload, indiferentemente de los muchos problemas, ilegalidades e injusticias que este proceso tuvo es importante notar que un buen numero de recursos de usuarios se perdieron, en la lucha legal por los servidores y su contenido, ya que estaban resguardados por la compañía megaupload, una vez que la compañía se vio afectada, todo el contenido resguardado por esta se vio afectado. En este mismo sentido las paginas personales fueron reemplazadas por entidades centrales que permitían, además del almacenamiento de información personal funciones de búsqueda similares a las de Google, es decir, a cambio de almacenar información personal en la pagina, se accede a esta misma información de otros usuarios, permitiendo hacer búsquedas, por ejemplo, de usuarios con el mismo cumpleaños, que estudiaron en la misma escuela, con los mimos gustos musicales, etc; esto solo era posible con la tecnología de la época hacerlo si se tenia el control de la misma base de datos, es decir, solo funciona con usuarios del mismo sitio web, éste es el origen de Facebook, sin embargo éste no fue el primer sitio en hacer uso de estas características (los sitios de geocities permitían hacer búsquedas en las paginas personales de geocities y MySpace permitía el diseño de paginas personales con las mismas funciones de búsqueda), fue, sin embargo, la primera en llamar la atención de los sociólogos como "Social Networking Sites", sitios web de red social (<a href="bibf">Boyd 2008</a>), sobre todo, porque mediante el uso de las características de búsqueda, colocación de mensajes públicos y funciones de mensajería "privada" entre usuarios, los sociólogos vieron analogías en la búsqueda de relaciones presentes en comunidades de adultos jóvenes (ir a fiestas y lugares públicos a buscar pareja, trabajo, etc). </p>
    <p id="tres"> Es de hacer notar que la aplicación de Internet para "Social Networking" o Redes Sociales, está presente desde la implementación de los primeros protocolos, lo primero que hicieron las universidades al conectar las computadoras mediante ARPANet fue aplicaciones de transmisión de mensajes (precursores del correo electronico), los Bulletin Board (BBS), cuyo uso se prolifero durante la década de 1970 y cuyo auge se mantuvo hasta los primeros años de la década de 1990, eran programas de computadora que permitían la colocación de mensajes públicos en una computadora compartida a los que se accedía haciendo que la computadora cliente llamara al numero de teléfono de la computadora que manejaba el boletín, tanto para dejar un mensaje como para retirar mensajes públicos, este mecanismo, permitía a los usuarios intercambiar software, datos, mensajes, y noticias unos con otros, buscar trabajo, ofrecer servicios, etc. para 1979, se había creado Usenet, un sistema de discusión que permitía a los usarios que se conectaran a él mediante internet colocar mensajes públicos; el vertiginoso crecimiento, auge y desarrollo de dos tecnologías añadirían popularidad al concepto de intercambio rápido entre los usuarios usando plataformas públicas: la migración de la plataforma telefónica a DSL (transmisión digital de las señales en la plataforma telefónica) permitió el desarrollo y disponibilidad de acceso a internet con altas velocidades (Banda Ancha) y el desarrollo de la tecnología celular, que llevó a los teléfonos a convertirse en computadoras de bolsillo con software preinstalado para conectarse a la Web (navegadores), la disponibilidad de ambas tecnologías llevaría a la creación de los sitios web de redes sociales (Social Networking Sites), sobre todo el desarrollo de la tecnología en teléfonos celulares tanto de las redes digitales EvDO y GSM como de los procesadores de bajo consumo en teléfonos llevaría al auge en el uso de estos dispositivos como mecanismos de conexión a la Web, dado el bajo poder de estos dispositivos, además de las peculiaridades de la red (la dirección IP otorgada a los dispositivos es local y no global) no es posible la instalación de aplicaciones distintas al navegador, es decir no es posible instalar programas servidor o hacer uso de otros protocolos, la proliferación de computadoras con Windows preinstalado harían lo mismo para las PCs, la dificultad para encontrar e instalar programas libres o gratuitos en estas computadoras jugarían un papel importante en la guerra de los navegadores, estos factores contribuirían al uso de "aplicaciones web", en lugar de usar aplicaciones locales en el dispositivo que se conecta a internet, se usaría el navegador para acceder a sitios que ofrecen servicios similares a lo que haría la aplicación, MySpace (2003), el otro sitio principal durante el primer auge de los sitios web de redes sociales, hacía posible y necesario diseñar la pagina personal, mientras que Facebook (2004) ofrecía mecanismos mas amigables a usuarios nuevos en aplicaciones web.</p>
    <p id="cinco"> De acuerdo a Forrester Research (<a href="#bib7">Montalbano, 2008</a>), 75% de los usuarios de Internet en el segundo cuarto de 2008, usaban "Social Media" (Medios Sociales, nombre dado por agencias de noticias a los sitios web de redes sociales, primero porque era más corto y segundo para hacer referencia al nuevo uso que los usuarios de estos sitios hacen de sus capacidades, la distribución de noticias de interés personal), uniéndose a sitios web de redes sociales, leyendo blogs o contribuyendo a reseñas de sitios de compra, en 2009, Facebook registró más de 175 millones de usuarios (el doble de la población de Alemania), cada minuto, 10 horas de contenido eran subidos a la plataforma de compartir videos Youtube y el sitio de almacenamiento y distribución de imágenes Flickr proveía acceso a mas de 3 mil millones de fotografías. El mayor cambio en la Decada de 2000 a 2010 fue, como se puede ver el incremento de mecanismos centralizados al acceder a contenidos en Internet, confiar tanto el trafico (Google), como la distribución de recursos (Mega), como la información personal a entes centralizados que se encargaron durante esta década de determinar la forma de la Web para muchos usuarios, para millones de usuarios, este es el Internet que conocen: la Web controlada por una pocas compañías, Google decide los recursos que se encuentran, servicios web como dropbox, depositfiles o mega, se encargan del almacenamiento y distribución de recursos (la dirección a estos recursos, se convirtió a su vez en efímera, debido a los términos de servicio) y los sitios de redes sociales deciden como comunicarse.</p>
    <p id="ocho"> La falta de privacidad, la censura, contaminación de lineas de tiempo (mensajes de odio, noticias falsas, material inapropiado apareciendo en las suscripciones de cuentas personales debido a auge momentáneo en tráfico de ese material) y cruzadas ideológicas para reportar mensajes de otras ideologías como inapropiados, son problemas que afectan las carteleras desde que estas existen, son inherentes a sus características, el interés de las empresas de hacer dinero de estos mecanismos, sin embargo, ha llevado a campañas publicitarias engañosas, los medios de noticias, llevados por estas campañas y, gracias a estos, gran cantidad de usuarios han colocado sobre estas carteleras y las empresas que las controlan una responsabilidad sobre su contenido, responsabilidad a las que estas empresas han respondido inadecuadamente. La migración de los usuarios de la cultura de televisión (consumo del contenido creado por grandes corporaciones) a los medios sociales (consumo del contenido creado por usuarios) hace necesario repensar el consumo de los medios, es necesario consumir contenido con pensamiento crítico y es necesario ser capaz de comprobar la legitimidad de contenido que se considere importante (como las noticias), en 2020, las empresas que controlan lo que los medios llaman medios sociales (Facebook, Twitter, Youtube e Instagram) no poseen herramientas para desarrollar ninguno de estos factores y el manejo de contenido se convierte en censura, la libertad de creación de contenidos se convierte en la post verdad, etc; sin incluir la privacidad que las empresas no pueden garantizar dado que son administradores de redes públicas, el uso de estas aplicaciones para resguardar contenido o comunicaciones privadas son un ejemplo de la falta de comprensión de las herramientas.  </p>
    <br>
    <h1>Preguntas Generadoras </h1>
    A partir del planteamiento de estos problemas surgen las interrogantes:
    <ul>
      <li> ¿Es posible hacer uso de aplicaciones de redes sociales en la Web, que respeten, simultáneamente la libertad, privacidad y decentralización? </li>
      <li> ¿Es posible hacer uso de redes sociales en la Web, con aplicaciones Web Descentralizadas? </li>
      <li> ¿Es posible legitimar contenido colocado en aplicaciones Web que sean parte de una Red Social? </li>
      <li> ¿Es posible la comprobación de hechos, referidos en contenidos colocado en aplicaciones Web que sean parte de una Red Social? </li>
    </ul>
    <br><br>
    <h1>Objetivos </h1>
    <ul>
      <li> Presentar un grupo de recomendaciones que incentiven el uso y desarrollo conciente y eficiente de aplicaciones de redes sociales en la Web, que respeten, simultáneamente la libertad, privacidad y decentralización. </li>
      <li> Desarrollar una batería de programas que permitan el uso y desarrollo de aplicaciones Web Decentralizadas para el uso y mantenimiento de redes sociales en la Web</li>
      <li> Presentar un grupo de recomendaciones que incentiven el uso y desarrollo conciente y eficiente de aplicaciones para la comprobación de identidades y legitimación de contenidods contendidos colocados en sitios web, parte de redes sociales. </li>
      <li> Desarrollar una batería de programas que permitan el uso y desarrollo de aplicaciones Web Decentralizadas para la emisión y comprobación de identidades y legitimación y comprobación de hechos en contenidos colocados en sitios web. </li>
    </ul>
    <br><br>
    <h1>Jutificación </h1>
    <p> El auge de los medios sociales ("Social Media"), en la última década ha transformado el consumo de información y contenido, hoy dia es posible el consumo de información organizada según gustos personales y tendencias, grupales, regionales o globales, es posible consumir varias horas de video diarias y que todo el contenido sea del gusto y preferencia del observador, un fenómeno imposible con los medios de emisión (radio, televisión), el precio que han pagado los usuarios por estas comodidades es ceder el control de la información personal que genera estos gustos, a grandes corporaciones que se hacen dueñas de esta información y la usan como capital (Los datos son el nuevo petróleo) y ceder el control sobre la elección de la forma en que el contenido llega al usuario, ambos factores son parte del mismo fenómeno la centralización de comunicación de mensajes y contenidos en las redes sociales por parte de pocas empresas privadas. Es necesario, por ello, demostrar que es posible mantener estas comodidades sin tales compromisos, consecuencia de este cambio será empoderar al usuarios a retomar el control de producción y consumo de contenido. </p>
    <p> En 2020, Venezuela ha sufrido durante más de una década acciones incrementales de bloqueo por parte del gobierno de Estados Unidos, en los últimos 5 años, estas acciones abarcaron el contenido social colocado en las paginas web de redes sociales (facebook.com, twitter.com e instagram.com), primero por parte de cruzadas ideológicas en las que grupos de usuarios reportaban material ideológicamente con el gobierno como inapropiado, luego, por parte de robots que, debido los reportes anteriores automatizaban el reporte de este contenido como inapropiado y finalmente en el último año por trabajadores de la empresa que han cancelado repetidamente cuentas gubernamentales, institucionales y personales con contenido ideológicamente alineado a la izquierda. La estrategia comunicacional del gobierno tinene más de una década usando medios electrónicos y poco más de una década usando cuentas twitter, primero para la transmisión de mensajes de carácter personal y no mucho después para mensajes institucionales, últimamente (desde hace 4 años), instituciones y grupos usan twitter.com como plataforma parte de su estrategia comunicacional, ante esta nueva responsabilidad, las herramientas de la plataforma, que no están diseñadas para este tipo de trabajo no han respondido adecuadamente ocasionando los problemas antes mencionados, por lo que se hace urgente y necesario, la creación de alternativas que permitan mantener las conexiones sociales que hoy dia incentivan estos sitios, pero siguiendo los principios de privacidad (y anonimato cuando este sea necesario), descentralización y verificación de identidad y hechos en los contenidos, pero manteniendo las comodidades en el consumo de información que facilitan los sitios web de las compañías que hoy dominan la industria de las redes sociales (Facebook, Twitter e Instagram).  </p>
    <p> La acumulación de problemas, originados del control y centralización por parte de compañías de redes sociales y medios de comunicación que usan sus aplicaciones, hace necesario la búsqueda de alternativas, es necesario por parte de grupos, gobiernos, instituciones y usuarios recuperar el control, tanto de la información personal (privacidad), como de la posibilidad de elegir conscientemente el contenido a consumir (libertad de elección), pero sobre todo es necesario la descentralización de las redes sociales, la transmisión de mensajes, y la publicación de contenido, han demostrado una tendencia histórica a crecer cuantitativamente y cualitativamente, mientras que los medios de producción se descentralizan. </p>
    <p> Al respecto, se han pronunciado tanto Vint Cerf (uno de los desarrolladores del Protocolo TCP/IP, lenguaje base de Internet) y Tim Berners Lee, desarrollador del protocolo HTTP (el grupo de ordenes que las computadoras conectadas a Internet usan para formar la Web), se han pronunciado repetidamente, más recientemente (<a href="#bib6">Charla en CERN, Junio de 2018</a>) Vint Cerf ha señalado que los problemas de privacidad y contenido impropio en las redes (que incluye el acoso y abuso del que son víctimas millones de jóvenes que hacen uso de las plataformas sociales pertenecientes sobre todo a la compañías Facebook, Google e Instagram) se debe a los patrones de uso que los usuarios han desarrollado en estos sitios Web, ha señalado que sobre estas compañías se ha puesto un gran peso (el manejo de contenido) porque las redes sociales se han centralizado; por su lado Berners-Lee en su carta abierta  (<a href="#bibb">Berners-Lee 2019</a>) con motivo de los 30 Años de la Web, ha señalado que es necesario que tanto las compañías como los gobiernos, como los usuarios se adhieran a principios que hagan posible el desarrollo de una Web segura, no presta a ser usada como arma. Ambos pioneros han señalado  (<a href="bibc">Berners-Lee 2018</a>, <a href="bib6">Cerf 2018</a>) que si bien la culpa del problema está en las compañías que no han poido manejar la gran responsabilidad que los patrones de uso de los usuarios han dado a sus sitios Web, la solución no está ni en ordenarle a las compañías con leyes y decretos (ya que sencillamente su contratarían un grupo de abogados cada vez más grande hasta encontrar hoyos legales que les permitan seguir trabajando de la misma forma) ni rogarle con peticiones (muy posiblemente se perderían en los millones de peticiones ya recibidas) que los resuelvan, la solución reside en la base de usuarios, tanto al cambiar los patrones de uso como al apoyo de herramientas alternativas que permitan mantener el maravilloso cumulo de conexiones humanas en que se ha transformado la Web, escapando del cúmulo de errores y problemas que el uso de los sitios web de información personal centralizada han originado.</p>
    <p> Existe para el año 2020, desde hace más de dos décadas, herramientas que hacen posible el mantenimiento de redes sociales fuera del control de las empresas que hoy controlan el mercado (Facebook, Google, Instagram y Twitter), demostrando no sólo que es posible escapar del control que estas empresas tienen sobre la información y contenido de millones de usuarios y la forma en que estos consumen contenido, sino que es posible mejorar la experiencia que los usuarios tienen al consumir contenido social en la Web, la descentralización ofrece no sólo soberanía sobre los datos sino mejorías en la experiencia de consumo de contenido.  </p>
    <p> Es de especial importancia para el desarrollo sostenible de la sociedad de la información la existencia de medios electrónicos usados para la publicación de contenidos, que tengan capacidades y características que permitan a sus usuarios verificar su origen (verificación de identidad) y legitimar su contenido, sin necesidad de organismos centralizados (ya que estos podrían muy bien manipular ambas verificaciones) o ceder sus libertades (el mecanismo de verificación de identidad debe estar separado de la identidad del usuario, es decir para verificar la identidad del autor de un contenido no es necesario exponer la propia identidad), pero que tengan facilidades y comodidades que permitan su uso casual en redes sociales. </p>
    <br><br>
    <h1> Desarrollo </h1>
    <p>En la búsqueda permanente por la descolonización epistemólogica del colectivo CURARE, la presente propuesta se encuentra enmarcada en el Método de la Cayapa (<a href="#biba">CURARE 2019</a>), aplicado al problema de la propagación de mensajes de odio, abusos, acosos y noticias falsas en las redes sociales, por lo que se procedió a aplicar el método de la S, al plantear, sumar expertos y presentar soluciones posibles a las comunidades.</p>
    <h2>Definición de la situación</h2>
    <p> Para definir la situación se realizó un estudio de casos disponibles en la Web, mediante la visita a los sitios web con aplicaciones de red social mas populares, estudiando sus caracteristicas y haciendo un arqueo bibliográfico sobre el problema como es presentado en los medios noticiosos, al respecto se encontraron las fuentes enunciadas en el título:Planteamiento del Problema, así mismo se hizo un estudio de las herramientas desarrolladas paralelamente al crecimiento de estos sitios web.</p>
    <h3><i>Contexto Histórico</i></h3>
    <p id="uno"> La Web es un mecanismo de intercambio de documentos que usa el stack TCP/IP de Internet como transporte entre computadoras (<a href="#bib1">Berners-Lee 1989</a>), el protocolo de este intercambio se denomina HTTP (<a href="#bib2">IETF 2014</a>)  y el formato de los documentos es HTML, aunque es posible usar el mecanismo para compartir otro tipo de documentos. Al momento de hacer la petición de un documento en una computadora esta es conocida como "servidor" y la computadora que hace la petición se denomina "cliente", estos roles son temporales y cualquier computadora con un programa que implemente la fase "servidor" del protocolo es capaz de servir documentos mediante HTTP, generalmente ambos roles son interpretados por programas distintos: un programa interpreta la fase "servidor" del protocolo (analizando peticiones, estableciendo un puerto de comunicaciones, etc) y es llamado "Servidor Web" y otro programa llamado navegador (aunque no necesariamente) se encarga de empaquetar peticiones, enviarlas al servidor e interpretar y graficar la respuesta, que según el mecanismo, puede ser un archivo HTML (pagina Web) u otro contenido, denominado recurso, estos recursos tienen identificadores únicos cuya forma se denomina URI  (<a href="#bib3">IETF 2005</a>)  y esta constituida por la especificación del protocolo (HTTP o HTTPS para conexiones HTTP encriptadas usando cifrado SSL), el nombre de dominio que es un alias asignado a la dirección IP de una computadora en una tabla compartida entre todas las computadoras que se conectan mediante Internet (DNS Global), o la dirección IP si no se tiene un alias o no se conoce y, siguiendo al carácter '/' el "sufijo", que es el conjunto de símbolos e identificadores (permitidos en RFC 3986) que informan al programa servidor del recurso que se requiere, estos URI (Universal Resource Identifiers, Identificadores de Recurso Universal) forman la base del mecanismo de "Hipertexto" de HTML, es decir partes del texto que una vez graficados e interpretados por el navegador se transforman en "Hipervínculos", partes del documento que hacen referencia a otros Recursos u otras partes del documento usando su URI, este Hipertexto es la justificación del nombre de la especificación de la forma que toman los documentos (HTML, Hyper Text Markup Language, o Lenguaje de Marcado para Hiper Texto) y su capacidad de vincular recursos explica por que se le denomina Web al mecanismo, ya que un recurso puede vincular a otro recurso que puede, hacer referencia al mismo recurso o a otro vinculando así documentos entre distintas computadoras y estableciendo así, conexiones entre estas computadoras y los autores de dichos documentos. El mecanismo que se describe es la Web, tanto las modificaciones al protocolo (HTTP 1.1, HTTP 2 y HTTP 3) como las modificaciones en el uso que se la hado al mecanismo (Web, Web 2.0 y Web 3.0) no han modificado estos factores que constituyen la base del mecanismo, cualquier computadora con un programa capaz de interpretar peticiones HTTP descritas en el RFC 7235 es capaz de servir documentos Web, siempre que se provea el URL y la computadora este conectada a internet (posea direccion IP publica accesible desde internet, etc), asi mismo, cualquier computadora capaz de elaborar peticiones e interpretar respuestas como estan descritas en el RFC 7235 es capaz de solicitar recursos siempre que este conectado a internet, se conozca el URI del recurso y este este accesible. </p>
    <p> Aunque los primeros en usar el mecanismo para compartir documentos fueron instituciones educativas y privadas, la sencillez y popularidad del mecanismo dieron origen a la proliferación de uso, primero por parte de entusiastas tecnológicos en la década de 1990 y muy rápidamente fue aprovechado por el publico en general para la creación de paginas personales, publicación de libros y documentos, transformando asi los mecanismos de publicación de trabajos científicos, literarios, diseño, fotografia y muchos otros, pero también por empresas, permitiendo que pequeñas empresas fueran capaces de abarcar que mercados imposibles de otra forma para empresas de su tamaño. Si bien la sencillez del mecanismo contribuyo enormemente a su popularidad, cualquier computadora de la era era capaz de ejecutar programas clientes de la Web, haciendo posible el acceso a contenido antes inaccesible, el principal componente de su transformación en una herramienta útil imprescindible en el surgimiento de la sociedad de información fue la Descentralización, todos los elementos de la sociedad que fueron transformados por la Web: Comercio, Publicación, Diseño, Fotografía, Educación (entre las transformaciones mas importantes), surgieron porque la Web permitió su descentralización, la publicación de un libro impreso es un proceso enormemente engorroso y costoso, la forma de llegar a la mayor cantidad de personas es usar un empresa de publicación grande y firmemente establecida, pero estas empresas tienen ventanas muy pequeñas de interés, en especial para material especifico, la web permitió el uso de internet para publicar sin necesidad de un intermediario, es imposible infra valorar la importancia de esta transformación, la proliferación de equipos computacionales de bajo costo confabulado con el fácil acceso a Internet permitió que cualquier persona publicara un documento y que cualquier persona lo pudiera acceder, el valor de la descentralización tomo al menos una década en calar en el publico en general, pero una vez lo hizo, se hizo incrementalmente fácil e incrementalmente habitual la creación de contenido "personal", para que una empresa de publicación decida publicar un libro, este tiene que apelar a un publico amplio, de modo de justificar los costos de imprenta, publicidad, distribución, etc, en la Web todos estos factores eran de importancia nula, lo que hizo posible publicar contenido que apelara a publicos reducidos y permitiendo la existencia de comunidades separadas geográficamente unidas, no por intereses comunes sino por un solo interés (Club de Fans, Álbumes personales de Fotografía, Libros de Interés Particular, Recursos Educativos, Manuales, etc). La Descentralización es un aspecto importante tanto de Internet, ya que muchos países han invertido grandes cantidades de dinero en Backbone de Internet (el conjunto de cables, dispositivos y mecanismos que hacen posible la transmisión global de señales entre computadoras, léase cables interoceánicos, fibra óptica, satélites, etc), se ha decidido que si bien hay comités mundiales para acordar especificaciones y protocolos (por ejemplo, el alias antes mencionado DNS) estos mecanismos no son propiedad de ningún país, es decir ningún autoridad puede decidir que un IP no se registre en el DNS global o imposibilitar a una maquina en particular, una IP o grupo de IP's su inserción en la red; pero es central a la Web, al fin y al cabo el vinculo entre documentos que forma la base de su mecanismo, es lo que determina su crecimiento, mientras mas vínculos más grande es la red. </p>
    <p id="tres"> El diseño descentralizado de la Web, sin embargo es un problema cuando no se conoce la URI del recurso que se esta buscando, o si se desean buscar grupos de recursos en vez de uno en especifico, a esto se denomina el problema de búsqueda, debido a que cualquier recurso puede ser puesto a la disposición de otras computadoras que se conecten a internet sin inscripción o registro, no hay forma de informar todos los nodos de la red que hay un recurso nuevo disponible o del cambio de un recurso existente, este es el objetivo de los buscadores, sitios web que corren multitud de programas encargados de crear índices de recursos disponibles en la red, obviamente no es posible crear un índice de todos los recursos puestos a la disposición de otras computadoras en internet (esto es una característica por diseño tanto de Internet como de la Web) por lo que es necesario ciertas heurísticas que ayudan a los buscadores asi como el registro intencional de empresas e instituciones que quieren ser encontrados, la última empresa en aprovechar una solución a este problema para crear una compañía exitosa (ganar dinero de la solución del problema) fue Google, cuyo modelo de negocios no ha cambiado desde sus comienzos: además de indizar el contenido de documentos en internet, Google indiza las entradas de los usuarios, analizando el texto de entrada para aplicar mecanismos heurísticos al ordenar los resultados, las empresas al pagar publicidad a la empresa, pagan por el uso de ambos índices que Google usa para ofrecer "Anuncios personalizados", es decir publicidad relacionada, no solo con el texto de búsqueda introducido sino textos anteriormente introducidos por el mismo usuario, la calidad de los índices (y de la publicidad ofrecida) depende enormemente de la cantidad de usuarios, mientras mas usuarios introduzcan texto, mejor será la predicción y la calidad de los índices, este modelo de negocios representa, sin embargo una amenaza a la descentralización de Internet, conocido en los medios noticiosos como el portal a Internet, la popularidad del buscador de la empresa Google, llevó a la invisibilidad de paginas que las reglas heurísticas del buscador no incluían, el direccionamiento de los resultados de búsqueda (ofreciendo no las opciones mas relevantes sino las mas populares o las que ofrecían mayor valor a la empresa), estos problemas persisten aún en 2020, que el buscador procesa mas de 5 mil millones de peticiones diarias.  </p>
    <p id="seis"> La Década entre 2010 y 2020 fue testigo de la realización de los problemas de privacidad de los métodos usados durante la década anterior, no fue sino hasta que los datos guardados en las empresas comenzaron a escapar de los confines de esta (mientras las empresas se hacen mas grande se hace mas difícil el control sobre sus datos), que las agencias de noticias llamarían la atención de los usuarios a los problemas de la centralización del almacén de datos personales y el trafico en la Web, es de hacer notas que estos problemas son inherentes al modelo de negocios de estas empresas y que los contratos de uso nunca ocultaron que los datos transferidos en estos sitios, si bien (algunas veces) no eran visibles a otros usuarios siempre lo son a la empresa, no solo eso, sino que son usados por la empresas para su modelo de negocios (publicidad), así Google usó hasta el 2014 los datos guardados en correos para alimentar sus algoritmos de predicción usados en sus mecanismos de venta de publicidad, Facebook usó las fotos guardadas en sus cuentas para alimentar algoritmos de reconocimiento de rostro que transformaría luego en un producto comercial, y todas estas funciones están dentro de los términos de uso que se aceptan al registrar estas cuentas, durante esta década y la anterior se advirtió repetidamente que estos sitios no respetan la privacidad pero hizo falta, de nuevo la atención de los medios noticiosos para hacer estas desventajas visibles (Caso Cambridge Analítica, Caso Snowden, etc). Al mismo tiempo, durante esta década proliferan los sitios alternativos, usados sobre todo por los jóvenes que buscaban retar el status quo, arqueos sucesivos demostrarían un patrón en el auge de los sitios web y aplicaciones con herramientas para el mantenimiento de las redes sociales, los jóvenes adolescentes, que representan una base de usuarios significativa (capaz de poner en auge un sitio web o aplicación), prefieren mantener sus redes sociales en sitios web y aplicaciones donde no estén sus padres (<a href="#bibe">Arce 2015</a>),  cuando Facebook se hizo el medio de redes sociales canónico, la masa de usuarios jóvenes migró el uso a la compañía twitter, donde Facebook ofrecía la busqueda y agrupacion al compartir información personal, el sitio web twitter se planteó como una plataforma de "micro blogging", un blog es una pagina personal que es actualizada por medio de reportes, es una forma de manejar esquemas de noticias en paginas personales, generalmente usando un manejador de contenido, las actualizaciones a su vez pueden ser anunciadas mediante mecanismos de suscripción como RSS, twitter.com ofrecía cuentas personales con la posibilidad de añadir reportes pequeños (120 caracteres, o letras en sus inicios), con un manejador de estos contenidos integrado en el sitio web, la novedad de la plataforma con respecto a los blogs personales es la centralización del mecanismo de suscripción (protocolo Pushhubbub) haciendo posible lineas de tiempo que permitían un manejo mas ágil de reportes de los usuarios y la agrupación de conexiones entre usuarios, no por datos personales sino por contenido de los reportes, para facilitar la búsqueda de reportes de usuarios, el sitio web empleaba palabras clave, que, después de la proliferación de su uso, los desarrolladores transformaron en el mecanismo Hashtag, añadiendo el símbolo numeral a la palabra clave permite facilitar su inidizacion y encontrar contenido con esa palabra clave mas rápido. Instagram se popularizó cuando twitter.com se convirtió en una plataforma canónica de transmisión de reportes, donde incluso instituciones y gobiernos hacen los propio, el sitio web Instagram es una plataforma de publicación de Fotos e imágenes (de ahí su nombre) que permitía la inclusion de palabras clave para facilitar su índice y búsqueda que vio su auge cuando el uso de twitter alcanzó masa crítica; en 2019, los sitios web de redes sociales Facebook, Twitter e Instagram son usados por instituciones, gobiernos y cadenas noticiosas para distribución de reportes, reportajes y mensajes institucionales, mientras que las redes sociales de jóvenes son mantenidas por aplicaciones de mensajería (Whatsapp, Telegram y Signal) o de redes sociales (Snapchat, Tik Tok).</p>
    <p id="siete"> La atención que atrajeron estas plataformas, por parte de instituciones, empresas y grupos, llamó la atención a la paradoja de la centralización en la publicación de mensajes: la censura. Las paginas personales son controladas por el contrato de términos de uso, generalmente estos contratos no incluyen términos sobre el contenido, en una plataforma de publicación de mensajes, sin embargo, se está publicando en una cartelera privada, cuyos mensajes son hechos públicos por el ente encargado de la cartelera, el control de estos mensajes se complica mientras aumenta el número de usuarios registrados, es importante notar que por razones de relaciones públicas, la empresa twitter se hace responsable de mantenimiento de contenidos en su página, es decir la empresa se hace responsable de mantener conexiones entre usuarios (lineas de tiempo), así como de remover mensajes "impropios" (y la línea de impropiedad es movible). Usuarios y entes de noticias (no habituados al trabajo en internet) han puesto la responsabilidad del contenido sobre los mantenedores de los sitios web. En la década entre 1990 y 2000, si una persona buscaba noticias en línea las leería directamente del blog o página web de una fuente preferida (por ejemplo un reportero preferido, una cadena noticiosa o un grupo con similares ideologías), en este sentido se estaba en control del contenido que se leía ya que había que tomar la decisión consciente de leer ese contenido dirigido por ese autor, hoy día, en cambio, de acuerdo a un reporte de Pew Research Center, Facebook dicta para la mayoría de adultos en Estados Unidos cuales noticias han de leer (<a href="#bib5">Pew Research 2019</a>),  tomando en cuenta que Facebook superó los 2 millones doscientos mil usuarios, millones de personas estan poniendo inmensas responsabilidades sobre esta empresa (o sobre sus usuarios) y el manejo de su contenido, sin embargo, en Australia, cuando la ACCC Australiana, sugirió que la compañía Facebook, compartiera ganancias por propagandas en su sitio Web cuando los usuarios lo usan para consumir contenido noticioso, como parte del diseño de un código de conducta para el manejo de las noticias en las redes sociales, después de que múltiples compañías de medios australianos cerraran o redujeran nómina durante la pandemia, la compañía se negó señalando que podrían cortar las noticias de su plataforma completamente sin afectar la base de usuarios o sus ganancias (<a href="#bib8">Zhou 2020</a>). Es importante destacar que aunque es indiscutible que los sitios web facebook.com y twitter.com son sitios web de redes sociales (<a href="#bibg">Obar 2015</a>) y el contenido que los usuarios colocan en estos sitios web representan los medios sociales (Social Media), ambos fenómenos, tanto las redes sociales como el social media, estan separados de aplicaciones particulares, el auge de nuevas aplicaciones de redes sociales lo evidencia, los medios de noticias sin embargo han aunado los terminos a plataformas y empresas particulares, haciendo los problemas que tienen estas empresas aún mas apremiantes.  </p>
    <h3><i>Redes Sociales y Medios Sociales</i></h3>
    <p>Según la definición ofrecida por Obar y Wildman en la edición especial de Telecomunications Policy, titulado "Governance of social media" (<a href="#bibg">Obar 2015</a>), y reflejada como fuente en el artículo de Social Media en el sitio web wikipedia.org, los medios sociales ("Social Media") comprenden los siguientes aspectos:</p>
    <ol>
      <li>
	<p><b>Aplicaciones Web cuyas característica de uso comprenden los patrones de uso denominados Web 2.0</b></p>
	<p>El uso de aplicaciones interactivas dentro de los sitios Web denominado Web 2.0 por los medios de consumo masivo (<a href="#bibh">Kaplan 2010</a>), ha permitido que la interacción de los usuarios con las paginas añada valor al contenido, los mecanismos de popularidad (de los cuales el primero fué mecanismo dig, en la página digg.com, que sería desplazado en la preferencia de los usuarios por reddit.com, heredado por el mecanismo Like de la página facebook.com, imitado por el mecanismo Favorito en la página twitter.com y reproducido en la mayoría de las plataformas usadas en el año 2020 para el uso y mantenimiento de las redes sociales en Internet), hacen posible que los usuarios no sean sólo consumidores de la información ofrecida sino partícipes de su difusión, popularidad y, mediante mecanismos de interacción, influyan en la producción de contenidos futuros.</p>
      </li>
      <li>
	<p><b>El contenido de los sitios Web de Medios Sociales ("Social Media") es generado por los usuarios del sitio web.</b></p>
	<p>El contenido se hace social mediante la interacción de los usuarios con el contenido, una vez colocado en los sitios web, denominados medios sociales, al contenido es añadido valor, mecanismos de difusión (compartir), mecanismos de popularidad (me gusta) y mecanismos de interacción (comentarios), este valor es aprovechado por lo usuarios para consumir en los sitios web de medios sociales (consumir contenidos mas populares o alineados a los gustos personales), por los creadores de contenido para la difusión de contenido y fluctúa en función de la interacción de los usuarios con el contenido. </p>
      </li>
      <li>
	<p><b>La identidad de los usuarios es mantenida por un perfil de usuario</b></p>
	<p>La función de conexión entre contenidos y usuarios es mantenida por el perfil, que crea la capacidad para las aplicaciones de medios sociales de emparejar preferencias y gustos reflejados en el perfil (no siempre ofrecidos de forma consciente por el usuario) con el contenido que se alinee a esas prefrencias, así mismo los perfiles forman la base de interacción entre usuarios y la interacción de usuarios con el contenido, de esta forma, las características de los medios sociales permiten rastrear autores de ediciones al contenido, usuarios que participaron en los mecanismos de interacción, difusión y popularidad. etc.</p>
      </li>
    </ol>   
    <p> En este sentido, el espacio de información al que pertenece el problema es el de la publicación y difusión de contenidos por parte de gobiernos, instituciones, grupos o particulares, que son fácilmente clasificados con herramientas de búsqueda, los contenidos son procesados para hacer reportes construidos a la medida de los usuarios, que para tal fin ofrecen información personal que es usada por las herramientas para la creación y mantenimiento de los reportes periódicos que ofrecen los sitios web. </p>
    <p> Este espacio de información cruza con los problemas presentados en el título: Planteamiento del problema, incluyendo pero no limitados a, visibilidad de contenido impropio (mensajes de odio), suplantación de identidad y difusión de contenidos sin origen legítimo (noticias falsas), uso impropio de los datos personales ofrecidos a los sitios web, creando problemas de acoso y abuso en las redes y uso de esta información por empresas inescrupulosas. </p>
    <p> Las comunidades estudiadas son aquellas representadas por los reportajes disponibles en línea presentados en el título: Planteamiento del problema, así como usuarios particulares pertenecientes a comunidades con las que el colectivo tiene contacto y el estudio de casos con usuarios institucionales con los que el colectivo ha tenido contacto el pasado.</p>
    <h2>Modelado de la situación</h2>
    <center><b>Diagnostico de la Situación Actual</b></center>
    <p>Espacio de Información: Difusión y consumo de contenidos creados por usuarios venezolanos e instituciones venezolanas usando los sitios web youtube.com (Google), facebook.com (Facebook), twitter.com (Twitter) e instagram.com (Instagram).</p>
    <table border=1 >
      <tr style="font-weight:bolder;font-family:'Sans';">
	<th style="width:10%;">Comunidad</th><th>Recursos</th><th>Unidad de Cuenta/Descripción de Cuenta (Problema reseñado*)</th>
      </tr>
      <tr>
	<td>Usuario Particular (Cuentas Personales)</td><td>Cuentas en sitios Web:<ul><li>youtube.com</li><li>twitter.com</li><li>facebook.com</li><li>instagram.com</li></ul></td><td><p>Condiciones de uso:<ul><li>Datos personales ofrecidos en el sitio web forman parte del capital de la empresa que administra el sitio web (Venta de datos personales a empresas de publicidad, Uso de datos ofrecidos por entes inescrupulosos para el abuso y acoso en línea). </li><li>Términos de uso movibles, condicionan el uso del sitio web y el acceso al contenido propio y de otros usuarios (Cierre de cuentas, Falta de acceso a contenidos en Youtube por localización o clasificación del contenido como sensible aun sin serlo)</li><li>Contenido colocado por los usuarios forma parte del capital de la empresa  que administra el sitio web. (Los creadores de contenido generan a la empresa ganancias de las que no toman parte, caso Youtubers, ACCC de Australia, etc).</li></ul></p>
	  <p>Patrones de uso por los usuarios:<ul><li>El contenido visible en las líneas de tiempo no es sólo el contenido de las suscripciones, sino el contenido que los administradores del sitio web o programas de automatización diseñados por estos (Contaminación de líneas de tiempo con difusión de mensajes de odio, noticias falsas y contenido impropio).</li><li>Acceso de información personal administrada por programas de automatización según conidciones conidicones cambiantes por la empresa que administra el sitio web (Falta de privacidad usada por acosadores y abusadores que hacen uso de los sitios web, Falta de control del usuario sobre la información personal - Funciones de Encriptación, Secreto Futuro).</li><li>Las funciones de bloqueo estan en manos de la empresa y los programas de automatización que estas han diseñado para tales fines (Tiempo de espera para bloquear usuarios, reporte falso de material impropio).</li></ul></p>
	</td>
      </tr>
      <tr>
	<td>Gobierno Nacional (Cuentas Institucionales)</td><td>Cuentas en sitios Web:<ul><li>youtube.com</li><li>twitter.com</li><li>facebook.com</li><li>instagram.com</li></ul></td><td>Condiciones de uso:<ul><li>Disponibilidad de la cuenta depende de condiciones que son privadas a la empresa. (Cierre masivo de cuentas por clasificación errónea como contenido impropio por robots, personas inescrupulosas o cruzadas ideológicas).</li><li>Términos de uso movibles, condicionan el uso del sitio web y el acceso al contenido propio y de otros usuarios. (Pérdida de contenido publicado)</li><li>Contenido colocado por los usuarios forma parte del capital de la empresa  que administra el sitio web</li></ul> </td>
      </tr>
      <tr>
	<td>Instituciones Vinculadas por Trabajo o Ideología al Gobierno Nacional (Cuentas Institucionales)</td><td>Cuentas en sitios Web:<ul><li>youtube.com</li><li>twitter.com</li><li>facebook.com</li><li>instagram.com</li></ul></td><td>Condiciones de uso:<ul><li>Disponibilidad de la cuenta depende de condiciones que son privadas a la empresa. (Cierre masivo de cuentas por clasificación errónea como contenido impropio por robots, personas inescrupulosas o cruzadas ideológicas).</li><li>Términos de uso movibles, condicionan el uso del sitio web y el acceso al contenido propio y de otros usuarios. (Pérdida de contenido publicado)</li><li>Contenido colocado por los usuarios forma parte del capital de la empresa  que administra el sitio web</li></ul> </td>
      </tr>
      <tr>
	<td colspan=6>*Por usuarios en los mismos sitios web o medios noticiosos tradicionales.</td>
      </tr>  
    </table>
    <p> Definido este espacio de información, se procede a señalar atributos operadicos en las funciones disponibles compatibles con las propiedades buscadas para la solución del problema de abusos y acoso en la red (privacidad y seguridad personal), limpieza de las líneas de tiempo de mensajes de odio (revisión de mensajes impropios en los contenidos) y noticias falsas (legitimación y certificación de identidades en los hechos en los contenidos) </p>
    <p></p>

    <p>En este espacio de información, no se encuentran suficientes recursos para garantizar las condiciones deseadas (Privacidad, Enfrentamiento al problema de la difusión de mensajes de odio, acoso y abuso en línea y difusión y propagación de noticias falsas por medio de falsificación de indentidades). Es necesario por lo tanto la exploracion de un espacio más amplio (búsqueda de alternativas). Se procedió por esto a la suma de expertos.</p>
    <h2>Captación de Información de los Expertos</h2>
    <p> A partir de la Definición de la Situación, se procede a hacer recomendaciones de alternativas basadas en herramientas libres, estudiando escenarios separados que contemplan el uso de la Web como herramientas para mantener redes sociales, la difusión y consumo de contenidos creados por usuarios y los mecanismos de suscripción para hacer esos contenidos accesibles a usuarios que desconozcan el URL de los contenidos creados.</p>
    <p><b></b></p>
    <h3><i>Mecanismos Propuestos para la Creación y Mantenimiento de Redes Sociales con usuarios conectados a Internet</i></h3>
    <p>Las nodos de la red estan representados tanto por los programas del computador personal, que se denominará fase fuera de línea del nodo en esta recomendación, asi denominada porque los programas funcionan sin necesidad de estar conectados a Internet, y la fase en linea del nodo, representada por la pagina del usuario en la Web.</p>
    <p> Los programa de la fase fuera de línea se encargan de la <b><i>Creación del Contenido</i></b>, comprende programas de edición de documentos en HTML, imagenes, videos, programas, etc., los programas que crearan los recursos a ser compartidos por el usuario cuando este esté en línea. La creación de contenido, no requiere de conexión a Internet.</p>
    <p> La fase en línea, se encarga de la <b><i>Publicación del Contenido</i></b> de mantener el perfil personal en la pagina del usuario, el dominio de esta página es el que se refleja en los URL que el usuario compartirá en la red, esta fase esta controlada por programas en linea fuera del control del usuario (pero con los que interactúa frecuentemente) y requiere estar en linea 100% del tiempo</p>
    <p>Las conexiones que representan la aplicación de herramientas para crear y mantener redes sociales con usuarios que están conectados a Internet, son establecidas al mantener vínculos es decir, la interacción de los programas de la fase online del usuario con el contenido de la fase online del usuario con el que se quiere hacer la conexión, estas conexiones tienen infinitas posbilidades de conexion en interaccion que son configuradas por los programas de la fase fuera de línea (bajo completo control del usuario).</p>
    
    <h2>Presentación de la Solución</h2>
    <h3><i>Escenario I. Publicación de Contenidos con características que permitan agregar valor una vez publicado</i></h3>
    <p>Inspirados por el compromiso de las Naciones Unidas reafirmado por la Asamblea General (<a href="#bibj">ONU 2015</a>) con la visión de la Sociedad de Información de construir una sociedad orientada al desarrollo inclusiva y centrada en la gente, donde todos y todas puedan crear, accesar, compartir y utilizar información y conocimiento, permitiendo a individuos, comunidades y pueblos alcanzar su potencial pleno en promover el desarrollo sustentable; inspirados igualmente por las nociones propuestas por el desarrollador del mecanismo subyacente a la Web, Tim Berners-Lee, anotado en el Principio 7 del contrato para la web (<a href="bibd">Berners-Lee 2019</a>), como parte de su carta abierta con razón del 30mo aniversario de la propuesta de su mecanismo de publicación de documentos y basados en la larga trayectoria de la publicación de documentos personales, se recomienda que cada usuario conectado a internet tenga al menos una y recomendablemente mas de una, página web personal.</p>
    <p>Actualmente hay multitud de opciones para la creacion de páginas web gratuitas o pagas, el principal atractivo de los sitios web más populares como herramientas de redes sociales, lease, youtube.com, facebook.com y twitter.com es la suscripción que las empresas llaman gratuita, sin embargo, la creación de cuentas y suscripción a sus servicios es un contrato de intercambio de datos personales y contenido por el acceso datos personales y contenidos de otras personas, no es gratis, sólo no hay intercambio de dinero, aún cuando, como es el caso de las agencias de noticias en facebook.com y twitter.com, artistas en instagram.com y twitter.com, creadores de contenido de video en youtube.com, etc. el contenido específico de algunos usuarios genera ganancias prominentes a la compañía. </p>
    <p> Es necesario definir el término página web personal, delimitando el adjetivo personal a <i>perteneciente</i> a un usuario en particular, que no incluye necesariamente la publicacion de información personal, es de especial relevancia, que los usuarios de Internet se conviertan en generadores de contenido y colaboradores sin, por ello, ceder el derecho a la privacidad, el derecho de autor, etc.</p>
    <p> Es caso especial el caso que ocupa la presente propuesta, ya que si bien las recomendacciones en este escenario se aplican globalmente a todos los usuarios conectados a Internet, en Venezuela, comunidades, colectivos, ciudadanos e instituciones se pueden sustentar en la Ley de Infogobierno, en sus artículos 70 y 71, para ejercer esfuerzos para garantizar la soberanía tecnológica, así mismo el artículo 71 garantiza el apoyo a "comunas de tecnologías libres, integradas por los usuarios, usuarias, activistas, colectivos y comunidades del software y hardware libres de la República Bolivariana de Venezuela" y lo artículos 74,75,76 y 77 describen el papel de la representación digital de la información para suplantar y circunvalar los obstáculos burocráticos, así como promover la visión del ecosocialismo (oficina sin papel). Para tal fin, la presente propuesta presenta las siguientes recomendaciones:</p>
    <p><b>Instalación de Panales de CURARE para la Creación y Mantenimiento de Páginas Personales:</b> La Fase en Línea ideal para un usuario conectado a Internet localizado geográficamente es que sus programas de mantenimiento en línea se encuentren geográficamente cercanos, la creación de nodos conectados a Internet que hagan de servidor localizados en la misma localidad, estado o región haría posible la respuesta rápida necesaria para la creación y publicación efectiva de contenido, indiferentemente de las acciones tomadas por compañías, grupos de usuarios o gobiernos extranjeros (bloqueo comunicacional), la instalación de nodos locales permitiría además aprovechar las posibilidades de enrutamiento alternativo de los protocolo TCP e IP permitiendo, acceso a contenidos cercanos por medios de transmisión alternativos (radio, telefono, cables, luz, etc.) y la creación de redes sin tráfico de ISP. </p>
    <p>Para el cumplimiento de estos objetivos la presentes recomendaciónes encuentran el panal CURARE especialmente apto para la satisfacción de expectatiovas en las condiciones de restricción de recursos en que se encuentran las comunidades (el bloqueo económico hace difícil la importación de los dispositivos electrónicos necesarios para las soluciones canónicas). Las funciones objeto del Panal CURARE, presentan las siguientes ventajas y características:</p>
    <ul>
      <li>Pequeña huella de memoria: Los objetos función están obtimizados para consumir flujos de datos del sistema con ventanas de tamaño adaptado a la memoria disponible (el conjunto de de funciones objetos haciendo de servidor web pueden funcionar consumiendo desde 1MB hasta 300MB de memoria)</li>
      <li>Bajo consumo de recursos de procesador: Cada función objeto tiene tiempos de espera y solapamiento de instancias adaptados al sistema al que se encuentran. El colectivo ha ejecutado pruebas exitosas en procesador ARM de un sólo núcleo funcionando a 700MHZ (Raspberry Pi 1 B), resultando en un servidor capaz de servir documentos de 300MB a 10 usuarios simuláneos con una experiencia de usuario transparente, de igual forma ha sido posible crear instancias capaces de servir 1GB y 10GB a mil y diez mil usuarios simultáneos adaptando el número de instancias, ventana de memoria, etc.</li>      
    </ul>
    <p> La Elección del Software a ejecutarse en los nodos dirigirá la elección de hardware del nodo, sin embargo, la forma de desarrollo y ejecución de las funciones objeto CURARE permiten adaptar el panal al hardware disponible haciendo nodos de equipos existentes. De este modo se asignan los siguientes roles al hardware disponible para componer un nodo:</p>
    <ul>
      <li><p><b>Almacenamiento:</b> Hardware y Software capaz almacenar y recuperar los datos requeridos por un nodo de la red con el ancho de banda requerido por el patrón de uso (acceso de recursos en la Web). En el caso en estudiado en la siguiente propuesta se estudian dos modos de mantener el contenido de la fase en línea, en el primero los nodos se encuentran donde se encuentra el usuario (contenido del computador personal puesto en línea) y este contenido se coloca como recurso disponible en Internet mediante el centro de enrutamiento más cercano de la comunidad, estos nodos se denominan nodos personales en estas recomendaciones y el almacenamiento de este nodo dependerá de los recursos disponibles en el computador o dispositivo conectado del usuario (usualmente más de 1GB), bajo éste metodo el problema de enrutamiento (IP pública) es resuleto mediante el almacenamiento en servidores públicos de tablas que correlacionan identidades con la IP que al momento de conectarse la identidad (por medio de un mensaje cifrado) publica, esto hace posible la conexión de nodos GSM (que no cuentan con dirección IP pública) y nodos conectados la red ABA (módem DSL), que no hayan apartado direcciones estáticas con la empresa. Éste metodo, sin embargo, es el más vulnerable a situaciones especiales (falta de acceso a la red, fallas eléctricas, etc). Como método de garantizar la disponibilidad del contenido se recomienda el almacenamiento de los recursos de los que se necesite garantizar la disponinilidad en sitios que ofrezcan hosting gratuito o pago, con la salvedad de considerar la dirección de estos recursos como efímera (aun cuando el servicio de hosting sea pago, el contenido está en el computador perteneciente a una empresa y los contratos de hosting generalmente son vagos en cuanto a garantizar la disponiblidad del contenido, aun cuando los términos sean claros no hay forma de obligar a empresas extranjeras a mantener los términos y estas empresas están atadas por leyes locales donde operan), no colocar recursos de carácter personal en estos sitios (al menos sin encriptación) y mantener la identidad separada de la dirección de recurso en el hosting. Tomando estas recomendaciones es posible establecer una identidad en la fase en linea compartida con suscriptores del contenido independiente del lugar donde este almacenado el contenido (computador personal, hosting pago, hosting gratuito, etc) y mantener el control de la publicación de éste (firma digital, encriptación).  </p>
	<p> El segundo modo de mantener la disponibilidad de los recursos en línea es la creación de centros de datos locales mantenidos por instituciones gubernamentales, institutos o comunidades, estos nodos se denominan nodos en línea en la presente recomendación, en este modos cada computador conectado al nodo tiene que tener la capacidad de ofrecer una página personal al menos a un usuario, tomando el promedio ofrecido por el mercado para páginas grauitas, la recomendación incluye un mínimo de 300MB y un maximo de 5GB para páginas personales gratuitas, lo que haría del hardware necesario para satisfacer el requerimiento promedio para servir páginas personales en 500GB por usuario servido, así se considera en la presente recomendación un nodo capaz de servir un millón de usuarios, que tendría que tener 1 Petabyte de almacenamiento disponible, esto es: 250 Disco duros de 4TB o 100 discos duros de 10TB, pero el tamaño específico dependerá de los requerimientos y capacidades de las instituciones gubernamentales, institutos o comunidades encargadas de la administración de tales nodos. El consumo de ancho de banda de tales requerimientos se hace demasiado alto para equipos de consumo masivo, computadoras de escritorio, que es la razón por la que la solución canónica requiere equipo especializado, la presente recomendación, sin embargo recomienda la aplicacióin de soluciones más económicas aplicando los objetos función del panal CURARE, haciendo un análisis de equipos disponibles por las instituciones encargadas o accesibles en el mercado (no afectados por el bloqueo económico), y aplicando el modelado de la situación del método de la Cayapa, modelar el software de acuerdo a los requermientos que se puedan satisfacer, así, actualmente es posible conseguir en el mercado no afectado por el bloqueo económico discos duros de 10TB pero no así discos de mayor densidad o equipos capaces de manejar el ancho de banda requerido, la solución incluiría entonces equipos de escritorio si se tienen estos equipos disponibles o mediante la división del trabajo con equipos de menor potencia, entre los cuales las tajetas de servidor basadas en núcleos ARM, tienen una relación precio - rendimiento muy aprovechable, discos de 10TB permiten aprovechar la relación densidad - precio de los discos de gran capacidad (soluciones empresariales), además de ofrecer solidez en el resguardo de datos, y un panal CURARE adaptado a maximizar el aprovechamiento de memoria y ancho de banda para servir a los requerimientos de acceso de los usuarios en la Web. En el ejemplo planteado 1 Petabyte serían satisfechos por 25 equipos (el equivalente de 2 CBITs de 15 computadoras, o 2 Laboratorios de computación de las Escuelas Bolivarianas de 20 computadoras), cada uno equipado con cuatro discos de 10TB, conectados al equipo con tecnología SATA y 2 GB de memoria, o bien 13 equipos con puertos PCIe donde sea accesible la adquisición de tarjetas de expasión PCIe de 8 puertos SATA, esta alternativa presenta como ventaja que los equipos pueden ser distribuidos geográficamente en las comunidades que requieran el acceso, es decir cada región podría estar conectada a un Centro de Datos propio y conectar éste tanto a la comunidad como a la red nacional y ésta al ISP, así el trafico podría manejarse intracomunal, intercomunal, nacional e Internet, maximizando así el tiempo de respuesta y minimizando el tráfico enrutado al ISP. Para la implementación de esta propuesta se consideran las siguientes alternativas comerciales:</p>
	<table>
	  <tr>
	    <th>Proveedor</th><th>Descripción</th><th>Cantidad Requerida (Escenario de 1 Petabyte/1 Millón de Usuarios) </th><th>Precio Unitario</th><th>Total</th>
	  </tr>
	  <tr>
	    <td>Seagate <a href="https://seagate.com">seagate.com</a></td><td><a href="https://www.seagate.com/files/www-content/datasheets/pdfs/exos-x-10DS1948-1-1709LA-es_LA.pdf">Segate Exos X10 (10TB)</a></td><td>100</td><td>80$</td><td>8000$</td>
	  </tr>
	  <tr>
	    <td colspan=10 style="background-color: #e5e5e5">Gama Alta</td>
	  </tr>
	  <tr>
	    <td>Linaro <a href="https://96boards.org">96boards.org</a></td><td><a href="https://www.96boards.org/product/developerbox/">SynQuacer Developerbox (Socionext SC2A11, 16GB DDR4-2133 RDIMM con ECC, LAN 1Gb/s, PCIe, mSATA)</a></td><td>6 (2 puertos SATA y dos tarjetas de Expansión 8 puertos SATA mediante conectores PCIe o conversores USB 3.0 ofrecen 18 puertos SATA por Equipo y los 16GB de Memoria DDR4 garantizan el ancho de banda necesario para el acceso a los datos)</td><td>1200$</td><td>8400$</td>
	  </tr>
	  <tr>
	    <td colspan=10 style="background-color: #e5e5e5">Gama Media</td>
	  </tr>
	  <tr>
	    <td>Linaro <a href="https://96boards.org">96boards.org</a></td><td><a href="https://www.96boards.org/product/poplar/">Poplar (Quad-core ARM Cortex-A53 64 bit Hisilicon Hi3798CV200, 2GB DDR3, LAN 1Gb/s, 1 conector PCIe)</a></td><td><ul><li><ul><li>13 (8 puertos mediante SATA en 1 tarjeta de Expansión a través de conector PCIe)</li><li>Tarjeta de Expansión SATA PCIe</li></ul></li><br><br><li><ul><li>7 (16 puertos SATA mediante 2 conversores USB 8 puertos en conectores USB 3.0)</li><li>Conversores USB 3.0 - SATA</li></ul></ul><br><br></td><td><ul><li><ul><li>80$</li><li>60$</li></ul></li></ul><br><br><ul><li><ul><li>80$</li><li>30$</li></ul></li></ul><br><br></td><td><ul><li><ul><li>1040$</li><li>780$</li></ul><p style="text-align:right;"><i><b>1820$</b></i></p></li><li><ul><li>560$</li><li>420$</li></ul></li><p style="text-align:right;"><i><b>980$</b></i></p></ul></td>
	  </tr>
	</table>
      </li>
      <li><b>Enrutamiento:</b>  Hardware y Software capaz de establecer las conexiones necesarias entre usuarios y recursos de intra o inter comunal, nacional o Internet, los equipos de enrutamiento deben tener la capacidad de comunicar tráfico entre usuarios de la red y entre usuarios de la red y el ISP. Para este fin la presente recomendación aconseja el uso de equipos capaces de establecer conexiones de 1Mb/s (cableado o inalámbrico) para el enrutamiento intercomunal, 1Gb/s para el enrutamiento intercomunal y 100 Mb/s para el enrutamiento de las comunidades con el ISP, estos equipos pueden ser Routers si están disponibles o tarjetas ARM capaces de ejecutar el Panal CURARE que puede ser configurado con fines de enrutamiento para aprovechar al máximo el uso de los recursos.</li>
    </ul>
    
    
    <h3><i>Escenario II. Publicación de Contenidos y Notificación a Usuarios Suscritos</i></h3>
    <p>http://dominio_usuario_1.paginagratis.com/blog_de_rantings</p>
    <p>http://dominio_usuario_2.paginagratis.com/paginas_que_recomiendo</p>
    <h4>Descripción del Escenario</h4>
    <ol>
      <li> El usuario_2 inserta en la fase fuera de línea (programas de descarga) la pagina blog_de_rantings de modo que sea notificado de sus cambios. Este mecanismo se demonina en esta recomendación sucripción.</li>
      <li>En la fase fuera de línea, el usuario1 crea contenido para actualizar la pagina blog_de_rantings.</li>
      <li>Cuando el usuario_1 esta en linea, se actualiza la pagina del blog_de_rantings. A este mecanismo se le denomina publicación en esta recomendación.</li>
      <li>Cuando el usuario_2 esta en linea, sus programas notan cambios en la pagina del blog_de_rantings y los notifica al usuario_2.</li>
      <li>El usuario_2 analiza el nuevo contenido y elabora en la fase fuera de línea (programas en la computadora del usuario) un comentario sobre el contenido, este es procesado y puesto en espera.</li>
      <li>Cuando el usuario_2 esta en linea, sube a su pagina de mensajes http://dominio_usuario_2.paginagratis.com/mis_comentarios el comentario sobre el contenido y le envia una notificacion por correo, o IRC si esta en linea en ese momento a usuario_1 para que lo revise.</li>
      <li>Un usuario_3 puede tener http://dominio_usuario_2.paginagratis.com/paginas_que_recomiendo en su lista de paginas a actualizar y, al leer la pagina de usuario_1 revisar http://dominio_usuario_2.paginagratis.com/mis_comentarios para verificar si hay un comentario sobre el contenido nuevo.</li>
    </ol>
    <p>Las conexiones entre usuario_1 y usuario_2 con usuario_3 son mantenidas por los programas del la fase fuera de línea de usuario_3 completamente bajo su control.
      Asi mismo usuario_2 solo verifica los cambios de la pagina personal de usuario_1 mientras le diga a sus programas que lo hagan, este mecanismo es diferente a los mecanismos PUSH (Protocolo Pubhubsubub) o incluso la lista de correos, donde la direccion de usuario_2 (e incluso de usuario_3) esta en manos del publicador (usuario_1) y este envia mensajes a los usuarios, en el caso del correo estos mensajes pueden o no ser cargados automaticamente pero siempre se descarga al menos el texto "asunto" del mensaje, en las plataformas de microblogging el mensaje se carga completamente, este mecanismo da origen no solo a Spam sino tambien a la "contaminacion" de lineas de tiempo en las plataformas de microblogging. Tambien es de hacer notar que el comentario de usuario_2 reside en su perfil y no en el perfil de usuario_1, esto circunvala el problema de los Trolls en la cartelera de mensajes de la pagina, el contenido de usuario_2 le pertenece a usuario_2 y por lo tanto solo es visible mediante peticiones a su pagina, mensajes de odio por ejemplo o con material que vaya contra el contrato del hosting haran q el contrato sea retirado de la pagina de usuario_2 y no de usuario_1.</p>
    <h4>Como funciona?</h4>
    <p> El mecanismo de suscripción es matenido por los usuarios (en el escenario propuesto usuario_2) que desean cosumir contenido regular de una fuente específica, para ello inserta en la fase fuera de línea (programas de descarga) la pagina blog_de_rantings de modo que sea notificado de sus cambios, para ello usuario_2 ejecuta un programa de examen de contenido HTML y descarga de vinculos (crawler) la implementación específica del mecanismo depende del programa usado para hacer las descargas, CURARE, recomienda el uso del <a href="https://curare2019.neocities.org/panal">panal de CURARE</a>, que tiene un grupo de objetos función para la automatización de cada caso específico (RSS, indices, etc.), sin embargo programas popularers libres y disponibles en línea son: httrack, cURL, wget, lynx, etc. el usuario dirige (entre las otras paginas que ha decidido analizar) a la URL http://dominio_usuario_1.paginagratis.com/blog_de_rantings el programa crawler cada vez q se conecta a internet, este programa podria, por ejemplo, examinar el contenido de la pagina http://dominio_usuario_1.paginagratis.com/blog_de_rantings sin descargar sus vinculos (analisis de pagina de indice) para revisar si ha habido algun cambio en el texto (por ejemplo, la insercion de un vinculo, o insercion de post), o revisar, mediante cabeceras Range Request (RFC 7235) el contenido en texto a partir de posiciones predeterminadas (p. ej, a partir del byte donde se noto el ultimo cambio), la escogencia de estas opciones dependerá de las propiedades del contenido en particular que se esta analizando y de las funcionalidades y características del programa utilizado (httrack se usa para descargar los vínculos en una página web, wget no soporta cabeceras Range Request, cURL es usado para descarar página), el  <a href="https://curare2019.neocities.org/panal">panal desarrollado por CURARE</a> tiene funciones objeto capaces de automatizar cada procedimiento mencionado.</p>
    <p> El usuario_1 hace las ediciones a su pagina blog_de_rantings con los editores en la fase fuera de línea.</p>
    <p> El mecanismo de publicación es mantenido por los programas en la computadora (o dispositivo) del autor (usuario_1, en el escneario presentado), usados para hacer las subidas, CURARE, recomienda el uso del panal de CURARE, que tiene un grupo de objetos función para la automatización tomando en cuenta una amplia gama de casos especiales, sin embargo programas populares libres y disponibles en línea son: cURL, git, gFTP, etc.  El usuario_1, estando en línea actualiza la URL http://dominio_usuario_1.paginagratis.com/blog_de_rantings con la nueva version del recurso.</p>
    <p> Al estar en linea, el mecanismo de suscripción de usuario_2 dirigido a http://dominio_usuario_1.paginagratis.com/blog_de_rantings, notifica al usuario de un cambio en el recurso http://dominio_usuario_1.paginagratis.com/blog_de_rantings.</p>
    <p> Para hacer un comentario sobre la pagina, el usuario_2 usa los programas de la fase fuera de línea para redactarlo.</p>
    <p> El usuario_2, estando en linea actualiza la URL http://dominio_usuario_2.paginagratis.com/mis_comentarios con la nueva version del recurso que contiene el comentario y la URL a la que se refiere el comentario.</p>

    <h3> Escenario III. Establecimiento y Verificación de Identidades</h3>
    <p> La presente recomendación considera necesario el mantenimiento de identidades que no perjudiquen el anonimato en la red, para un grupo de usuarios como Instituciones Gubernamentales, Intituciones No Gubernamentales, Institutos, Empresas, Organizaciones o Personas que por una u otra razón decidan hacerlo (para los usuarios particulares, esto no es recomendado), es necesaria la correlación de la identidad aceptada por las comunidades afectadas en su etapa fuera de línea, es decir, asegurarse que la cuenta que difunde contenido tomando la autoridad de un ministerio en realidad pertenezca a la intitución ministerial, por otro lado para un grupo de usuarios conectados a la red (bien sea Internet o Redes locales) también es necesario el mantenimiento de identidades separadas de auqellas mantenidas fuera de la red (el publicador de blogs que filtren información peligrosa puede identificarse como el autor del blog sin proporcionar información personal). En la presente recomendación se aconseja el uso de metodos criptográficos asimétricos garantizar la identidad, para ello es necesario lograr un equilibrio entre el algoritmo más fuerte disponible para el usuario que desea crear la identidad, y la disponibilidad al mayor número de usuarios para permirtirles comprobarla.</p>
    <p> El uso de métodos criptográficos asimétricos para la creación, mantenimiento y verificación de identidades permite a los usuarios en Internet Legitimar contenidos, así agencias de noticias (o particulares que quieran compartir hechos noticiosos), tienen la capacidad de presentar contenidos firmados provenientes de instituciones para dar legitimidad al contenido compartido, como ejemplo, se pueden considerar comentarios a un decreto ministerial, ofreciendo un viculo al documento original o, presentando partes firmadas publicadas por el ente, evitando así la circulación de material falsificado que tanto daño a causado a usuarios e instituciones.</p>
    <h4>Descripción del Escenario</h4>
    <p>En la fase fuera de línea (es importante, relevante y necesario que esto no se haga mediante servicios en línea y que al hacerlo, el dispositivo que ejecuta los programas correspondientes no esté conectado a ninguna red), usuario_1, crea por medio de las acciones requeridas por el algoritmo, claves privada y pública, y resguarda la clave privada en un lugar seguro accesible sólo cuando sea necesaria.</p>
    <p>En la fase en línea, el usuario coloca en http://dominio_usuario_2.paginagratis.com sólo la clave pública y la hace accesible y visible al mayor número de usuarios (notifica a usuarios suscritos al contenido, la anvía como firma en los correos, etc). </p>
    <p>En la fase en línea, usuario_2 consume contenidos publicados por usuario_3 que hacen referencia a contenido de usuario_2, si este desea verificar su proveniencia, es decir que el contenido publicado por usuario_3 en realidad ha sido producido por usuario_2, no tiene más que ir a su página y correr el programa de verificación correspondiente al algoritmo usado, usando como argumento la clave proveída en su página web o enviada en los contenidos de suscripción.</p>
    <h4>Como funciona?</h4>
    <p>El mecanismo de criptografía asimétrica, permite compartir la clave en dos partes, una secreta que se usa para desencriptar contenido, que permite la privacidad de los mensajes, es decir, sólo la persona a la que el contenido es enviafo es capaz de decodificar la información, y una clave pública que se usa para encriptar el contenido de modo que sólo el usuario que posee la clave privada creada junto con la clave pública usada pueda decodificar el contenido. Este mecanismo se usa a la inversa para firmar contenido, de modo que un usuario con la clave pública es capaz de aseurar que el contenido viene del usuario con esa clave secreta a la que corresponde esa clave pública. El algoritmo que esta recomendación aconseja usar es RSA por el fácil acceso y gran disponibilidad.</p>
    <p></p>

    <h1> Bibliografía </h1>
    <p><a name="bibe">Arce, N. (2014)</a>. Facebook dying?, Survey suggests teens prefer Instagram and Twitter more. Techtimes.com, [Revista en Línea]. Disponible en: <a href="http://www.techtimes.com/articles/17682/20141011/facebook-diying-survey-suggests-teens-prefer-twitter-and-instagram-more.htm">http://www.techtimes.com/articles/17682/20141011/facebook-diying-survey-suggests-teens-prefer-twitter-and-instagram-more.htm</a>. Consultado el 10 de Julio de 2020.</p>
    <p><a name="bib1">Berners-Lee Tim</a>. (1989). <i>Proposal for an information management system</i>, [Documento en Línea]. Disponible en: <a href="http://info.cern.ch/Proposal.html">http://info.cern.ch/Proposal.html</a>. Consultado el 10 de Julio de 2020.</p>
    <p><a name="bibc">Berners-Lee Tim</a>. (2018). The web can be weaponised – and we can't count on big tech to stop it. [Documento en Línea]. Disponible en:<a href="https://www.theguardian.com/commentisfree/2018/mar/12/tim-berners-lee-web-weapon-regulation-open-letter">https://www.theguardian.com/commentisfree/2018/mar/12/tim-berners-lee-web-weapon-regulation-open-letter</a>.</p>
    <p><a name="bibb">Berners-Lee Tim</a>. (2019). 30 years on, what’s next #ForTheWeb?. [Documento en Línea]. Disponible en: <a href="https://webfoundation.org/2019/03/web-birthday-30">https://webfoundation.org/2019/03/web-birthday-30</a>.</p>
    <p><a name="bibd">Berners-Lee Tim</a>. (2019). CONTRACT FOR THE WEB. [Documento en Línea]. Disponible en:<a href="https://contractfortheweb.org">https://contractfortheweb.org</a>.</p>
    <p><a name="bibf">Boyd, D. y Ellison, N.B. (2008).  </a> Social networking sites: Definition, history, and scholarship. Journal o Computing-Mediated Communication. </p>
    <p><a name="biba">CURARE. (2019)</a>. La Cayapa: El Método del Panal. [Documento en Línea]. Disponible en:<a href="https://curare2019.neocities.org/metodo.pdf">https://curare2019.neocities.org/metodo.pdf</a>.</p>
    <p><a name="bib8">Elizabeth Montalbano</a>. Forrester: Social networking grows up. IDG News Service. [Revista en Línea]. Disponible en: <a href="https://www.computerworld.com/article/2527588/forrester--social-networking-grows-up.html">https://www.computerworld.com/article/2527588/forrester--social-networking-grows-up.html</a>. Consultado el 10 de Julio de 2020.</p>
    <p><a name="bib3">Internet Engineering Task Force</a>. (2005). Request for Comments: 3986, [Documento en Línea]. Disponible en: <a href="http://tools.ietf.org/rfc/rfc3986.txt">http://tools.ietf.org/rfc/rfc7235.txt</a>. Consultado el 10 de Julio de 2020.</p>
    <p><a name="bib2">Internet Engineering Task Force</a>. (2014). Request for Comments: 7235, [Documento en Línea]. Disponible en: <a href="http://tools.ietf.org/rfc/rfc7235.txt">http://tools.ietf.org/rfc/rfc7235.txt</a>. Consultado el 10 de Julio de 2020.</p>
    <p><a name="bibh">Kaplan Andreas M.; Haenlein Michael. (2010)</a>. "Users of the world, unite! The challenges and opportunities of social media". Business Horizons. [Documento en Línea]. Disponible en:<a href="https://doi.org/10.1016%2Fj.bushor.2009.09.003">doi:10.1016/j.bushor.2009.09.003</a>.</p>
    <p><a name="bib6">Kate Kahle</a>. Big data and social media. CERN. [Revista en Línea]. Disponible en: <a href="https://cds.cern.ch/record/2628037">https://cds.cern.ch/record/2628037</a>. Consultado el 10 de Julio de 2020.</p>
    <p><a name="bibk">Ley de Infogobierno</a>. (2013). Gaceta Oficial de la República Bolivariana de Venezuela 40.724. [Documento en Línea]. Disponible en:<a href="http://www.conatel.gob.ve/wp-content/uploads/2014/10/PDF-Ley-de-Infogobierno.pdf">http://www.conatel.gob.ve/wp-content/uploads/2014/10/PDF-Ley-de-Infogobierno.pdf</a>.</p>
    <p><a name="bibj">Naciones Unidas. (2015)</a>. Reunión de la Asamblea General para la Revisión de la Implementación de los Resultados de la Reunión de Alto NIvel sobre la Sociedad de Información. [Documento en Línea]. Disponible en:<a href="http://undocs.org/A/60/687">http://undocs.org/A/60/687</a>.</p>
    <p><a name="bibg">Obar, Jonathan A.; Wildman, Steve (2015)</a>. Social media definition and the governance challenge: An introduction to the special issue. Telecommunications Policy. [Documento en Línea]. Disponible en:<a href="https://doi.org/10.1016%2Fj.telpol.2015.07.014">https://doi.org/10.1016%2Fj.telpol.2015.07.014</a>.</p>
    <p><a name="bib5">Pew Research Center</a>. (2019). 10 facts about Americans and Facebook. [Página web en Línea]. Disponible en: <a href="https://www.pewresearch.org/fact-tank/2019/05/16/facts-about-americans-and-facebook/">https://www.pewresearch.org/fact-tank/2019/05/16/facts-about-americans-and-facebook</a>. Consultado el 10 de Julio de 2020.</p>
    <p><a name="bib4">Singel, Ryan</a>. (2012). Vint Cerf: We Knew What We Were Unleashing on the World. WIRED. [Revista en Línea]. Disponible en: <a href="https://www.wired.com/2012/04/epicenter-isoc-famers-qa-cerf">https://www.wired.com/2012/04/epicenter-isoc-famers-qa-cerf</a>. Consultado el 10 de Julio de 2020.</p>
    <p><a name="bib7">Tere Vadén. </a>The Hacker Community and Ethics: An Interview with Richard M. Stallman. Tampere University Press. 2002. [Página web en Línea]. Disponible en: <a href="https://www.gnu.org/philosophy/rms-hack.html">https://www.gnu.org/philosophy/rms-hack.html</a>. Consultado el 10 de Julio de 2020.</p>
    <p><a name="bib9">Zhou, Naaman; Meade, Amanda.</a>Facebook says it doesn’t need news stories for its business and won’t pay to share them in Australia. The Guardian, 2020. [Documento en Línea]. Disponible en: <a href="https://www.theguardian.com/media/2020/jun/15/facebook-says-it-doesnt-need-news-stories-for-its-business-and-wont-pay-to-share-them-in-australia">https://www.theguardian.com/media/2020/jun/15/facebook-says-it-doesnt-need-news-stories-for-its-business-and-wont-pay-to-share-them-in-australia</a>. Consultado el 10 de Julio de 2020.</p>
    <hr>
    <hr>
    <hr>
    <div style="display:none">
    </div>

  </body>
</html>
